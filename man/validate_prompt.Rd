% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/main.R
\name{validate_prompt}
\alias{validate_prompt}
\title{Validate and Preview Custom Prompt Output}
\usage{
validate_prompt(
  openai.API = NULL,
  groq.API = NULL,
  user.prompts = NULL,
  N.runs = 3,
  model = "gpt3.5",
  top.p = 1,
  temperature = 1,
  system.role = NULL,
  silently = FALSE
)
}
\arguments{
\item{openai.API}{Optional (Required if using a GPT model). A character string containing your OpenAI API key.}

\item{groq.API}{Optional (Required if using a Groq model). A character string containing your Groq API key.}

\item{user.prompts}{A named list of custom prompt strings for each item type.}

\item{N.runs}{An integer specifying the number of times to run the prompt for preview; defaults to \code{3}.}

\item{model}{A character string specifying the language model to use. Options include \code{"gpt3.5"}, \code{"gpt4o"},
\code{"llama3"}, \code{"mixtral"}, \code{"deepseek"}, or \code{"gemma2"}. Defaults to \code{"gpt3.5"}.}

\item{top.p}{Numeric; defaults to \code{1}. Sets the top-p sampling parameter for the language model.}

\item{temperature}{Numeric; defaults to \code{1}. Controls the randomness of the model's output (valid range: 0â€“2).}

\item{system.role}{Optional. A character string defining the role of the language model (e.g., "an expert methodologist").}

\item{silently}{Logical; defaults to \code{FALSE}. If \code{TRUE}, suppresses console output.}
}
\value{
The sample output generated by the language model as produced by your prompts. The structure of the output depends on your custom prompts, the chosen language model, and model settings (i.e., temperature and top-p).
}
\description{
This function is designed to test and preview the output generated by your custom prompts before proceeding with full-scale item generation via \code{AIGENIE}.
It validates that all required inputs (API keys, custom prompts, and numerical parameters) are provided and correctly formatted.
Then, it calls \code{generate_output} to produce sample output from the language model.
This preview helps ensure that the output conforms to the expected format, which is crucial for your cleaning function to operate correctly
and for the final generated items to meet your requirements before generating a large number of items via \code{AIGENIE}.
}
\examples{
\dontrun{
  # Example: Preview the output from custom prompts before generating items

  # Replace with your actual OpenAI API key
  key <- "INSERT YOUR KEY HERE"

  # Define custom prompts for two traits (e.g., "extraversion" and "openness")
  custom_prompts <- list(
    extraversion = "Generate three unique, psychometrically robust items to measure extraversion from the Big Five model of personality. Use the format: <extraversion>: <item statement>.",
    openness = "Generate three unique, psychometrically robust items to measure openness from the Big Five model of personality. Use the format: <openness>: <item statement>."
  )

  # Define a system role that instructs the language model on how to behave
  system_role <- "You are an expert psychometrician specialized in scale development."

  # Run the validation to preview the prompt output. This helps ensure the output is formatted as expected.
  test_output <- validate_prompt(
    openai.API = key,
    user.prompts = custom_prompts,
    system.role = system_role
  )

  # Print the output to inspect its format
  print(test_output)

########################################################################
###### Or, Run Validate Prompt with an Open Source Model via Groq ######
########################################################################

# Add your API Key from Groq
groq.key <- "INSERT YOUR GROQ API KEY"

# Chose between 'Mixtral', 'Gemma 2', 'Llama 3', or 'DeepSeek'
open.source.model <- "mixtral"

  test_output_open_source <- validate_prompt(
    groq.API = groq.key,
    user.prompts = custom_prompts,
    model = open.source.model,
    system.role = system_role
  )


# Print the output to inspect its format
print(test_output_open_source)

}
}
